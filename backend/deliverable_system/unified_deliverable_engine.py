# backend/deliverable_system/unified_deliverable_engine.py
"""
Unified Deliverable Engine - Enhanced with Real Asset Extraction
"""

import asyncio
import logging
import json
import os
from datetime import datetime
from typing import Dict, Any, Optional, List

from database_asset_extensions import asset_db_manager
from .requirements_generator import requirements_generator
from .concrete_asset_extractor import concrete_asset_extractor
from .intelligent_aggregator import intelligent_aggregator

logger = logging.getLogger(__name__)

class UnifiedDeliverableEngine:
    """Unified Deliverable Engine with real asset extraction and intelligent aggregation"""
    
    def __init__(self):
        logger.info("ðŸ”§ Unified Deliverable Engine initialized with full capabilities")
        self.db_manager = asset_db_manager
        self.requirements_generator = requirements_generator
        self.asset_extractor = concrete_asset_extractor
        self.aggregator = intelligent_aggregator

    async def generate_requirements_from_goal(self, goal):
        return await self.requirements_generator.generate_requirements_from_goal(goal)

    async def extract_assets(self, content: str, context: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """Extract real assets from content using AI-powered extraction"""
        return await self.asset_extractor.extract_assets(content, context)

    def process_deliverable(self, content: str) -> Dict[str, Any]:
        """Process deliverable content"""
        return {"status": "processed", "content": content}

    async def stop(self):
        """Stops the engine and cleans up resources."""
        logger.info("Unified Deliverable Engine stopped.")
        pass

# Create singleton instance
unified_deliverable_engine = UnifiedDeliverableEngine()

# Goal-specific deliverable creation
async def create_goal_specific_deliverable(workspace_id: str, goal_id: str, force: bool = False) -> Optional[Dict[str, Any]]:
    """Creates a deliverable for a specific goal from its completed tasks"""
    logger.info(f"ðŸŽ¯ Creating goal-specific deliverable for goal {goal_id} in workspace {workspace_id}")
    
    try:
        from database import list_tasks, create_deliverable, get_deliverables
        import json
        
        # Get completed tasks for this specific goal
        completed_tasks = await list_tasks(workspace_id, status="completed", goal_id=goal_id)
        
        if not completed_tasks:
            logger.info(f"No completed tasks found for goal {goal_id}")
            return None
        
        # Check if this goal already has deliverables
        existing_goal_deliverables = await get_deliverables(workspace_id, goal_id=goal_id)
        max_deliverables_per_goal = int(os.getenv("MAX_DELIVERABLES_PER_GOAL", 1))
        
        if len(existing_goal_deliverables) >= max_deliverables_per_goal and not force:
            logger.info(f"Goal {goal_id} already has {len(existing_goal_deliverables)} deliverables (max: {max_deliverables_per_goal})")
            return None
            
        # Get goal information for better naming
        from database import get_workspace_goals
        goals = await get_workspace_goals(workspace_id)
        goal_info = next((g for g in goals if g['id'] == goal_id), None)
        goal_description = goal_info.get('description', goal_info.get('metric_type', 'Goal')) if goal_info else 'Goal'
        
        logger.info(f"âœ… Creating goal-specific deliverable from {len(completed_tasks)} completed tasks for goal: {goal_description}")
        
        # Aggregate task results for this goal
        aggregated_content, aggregation_quality_score = await _aggregate_task_results(completed_tasks)
        
        # If aggregation quality is low, create a specific warning deliverable
        if aggregation_quality_score < 50:
            logger.warning(f"âš ï¸ Low quality aggregation for goal {goal_id}. Score: {aggregation_quality_score}. Creating a warning deliverable.")
            deliverable_data = {
                "title": f"Review Required: {goal_description}",
                "type": "low_value_warning",
                "content": f"""# Business Value Warning

**Goal:** {goal_description}

**Analysis:** The system detected that the completed tasks for this goal did not produce a final, concrete business asset. The results consisted primarily of plans, outlines, or templates rather than ready-to-use content.

**Reason:** The initial tasks generated by the AI planner were likely too abstract.

**Recommendation:** This is an architectural issue being resolved. The AI planner is being updated to generate more specific, data-driven tasks to prevent this in the future. No manual action is required at this time.""",
                "status": "needs_review",
                "goal_id": goal_id,
                "business_value_score": aggregation_quality_score,
                "metadata": { "source": "low_quality_aggregation_warning" }
            }
        else:
            # Create goal-specific deliverable
            deliverable_data = {
                "title": f"{goal_description} - AI-Generated Deliverable",
                "type": "goal_deliverable",
                "content": aggregated_content,
                "status": "completed",
                "goal_id": goal_id,  # CRITICAL: Link to specific goal
                "readiness_score": 90,
                "completion_percentage": 100,
                "business_value_score": aggregation_quality_score,
                "quality_metrics": {
                    "task_count": len(completed_tasks),
                    "content_length": len(str(aggregated_content)),
                    "created_from": "goal_task_aggregation",
                    "goal_id": goal_id
                },
                "metadata": {
                    "source": "goal_specific_aggregation",
                    "goal_description": goal_description,
                    "tasks_included": [task.get('id') for task in completed_tasks],
                    "creation_method": "automated_goal_completion"
                }
            }
        
        # Create the deliverable in database
        created_deliverable = await create_deliverable(workspace_id, deliverable_data)
        
        if created_deliverable:
            logger.info(f"ðŸŽ‰ Successfully created goal-specific deliverable: {created_deliverable.get('id')}")
            return created_deliverable
        else:
            logger.error(f"âŒ Failed to create goal-specific deliverable for goal {goal_id}")
            return None
            
    except Exception as e:
        logger.error(f"Error creating goal-specific deliverable: {e}", exc_info=True)
        return None

async def _create_goal_specific_deliverables_for_workspace(workspace_id: str, force: bool = False) -> Optional[Dict[str, Any]]:
    """Creates goal-specific deliverables for all eligible goals in a workspace"""
    logger.info(f"ðŸŽ¯ Creating goal-specific deliverables for workspace {workspace_id}")
    
    try:
        from database import get_workspace_goals
        
        # Get all goals for this workspace
        goals = await get_workspace_goals(workspace_id)
        
        if not goals:
            logger.info(f"No goals found for workspace {workspace_id}")
            return None
            
        created_deliverables = []
        
        for goal in goals:
            goal_id = goal.get('id')
            goal_description = goal.get('description', goal.get('metric_type', 'Unknown Goal'))
            
            # Check if this goal has completed tasks
            from database import list_tasks
            completed_tasks = await list_tasks(workspace_id, status="completed", goal_id=goal_id)
            
            if not completed_tasks:
                logger.debug(f"Goal {goal_description} has no completed tasks, skipping")
                continue
                
            # Check if this goal already has deliverables
            from database import get_deliverables
            existing_goal_deliverables = await get_deliverables(workspace_id, goal_id=goal_id)
            
            if existing_goal_deliverables and not force:
                logger.debug(f"Goal {goal_description} already has deliverables, skipping")
                continue
                
            logger.info(f"ðŸŽ¯ Creating deliverable for goal: {goal_description} ({len(completed_tasks)} tasks)")
            
            # Create deliverable for this goal
            goal_deliverable = await create_goal_specific_deliverable(workspace_id, goal_id, force)
            
            if goal_deliverable:
                created_deliverables.append(goal_deliverable)
                logger.info(f"âœ… Created deliverable for goal: {goal_description}")
            else:
                logger.warning(f"âŒ Failed to create deliverable for goal: {goal_description}")
        
        if created_deliverables:
            logger.info(f"ðŸŽ‰ Successfully created {len(created_deliverables)} goal-specific deliverables")
            return created_deliverables[0]  # Return first created deliverable for compatibility
        else:
            logger.info(f"No goal-specific deliverables were created for workspace {workspace_id}")
            return None
            
    except Exception as e:
        logger.error(f"Error creating goal-specific deliverables for workspace: {e}", exc_info=True)
        return None

# Backward compatibility functions  
async def check_and_create_final_deliverable(workspace_id: str, deliverable_context: dict = None, force: bool = False):
    """Real deliverable creation from completed tasks - ENHANCED for goal-specific creation"""
    logger.info(f"ðŸ” check_and_create_final_deliverable called for workspace {workspace_id} (force={force})")
    
    try:
        # Import required modules
        from database import list_tasks, create_deliverable, get_deliverables
        import json
        
        # NEW: Check if we should create goal-specific deliverables
        should_create_goal_specific = os.getenv("ENABLE_GOAL_SPECIFIC_DELIVERABLES", "true").lower() == "true"
        
        if should_create_goal_specific:
            return await _create_goal_specific_deliverables_for_workspace(workspace_id, force)
        
        # FALLBACK: Original workspace-level logic
        # Get completed tasks for this workspace
        completed_tasks = await list_tasks(workspace_id, status="completed")
        
        if not completed_tasks:
            logger.info(f"No completed tasks found for workspace {workspace_id}")
            return None
            
        # Check if we already have deliverables
        existing_deliverables = await get_deliverables(workspace_id)
        
        # Respect limits even when forced
        max_deliverables = int(os.getenv("MAX_DELIVERABLES_PER_WORKSPACE", 3))
        if len(completed_tasks) >= 1 and len(existing_deliverables) < max_deliverables:
            logger.info(f"âœ… Creating deliverable from {len(completed_tasks)} completed tasks")
            
            # Aggregate task results
            aggregated_content = await _aggregate_task_results(completed_tasks)
            
            # Create deliverable
            deliverable_data = {
                "title": f"Project Deliverable - {len(completed_tasks)} Tasks Completed",
                "type": "project_summary",
                "content": aggregated_content,
                "status": "completed",
                "readiness_score": 85,
                "completion_percentage": 100,
                "business_value_score": 80,
                "quality_metrics": {
                    "task_count": len(completed_tasks),
                    "content_length": len(aggregated_content),
                    "created_from": "task_aggregation"
                },
                "metadata": {
                    "source_tasks": [task.get("id") for task in completed_tasks],
                    "creation_method": "automated_aggregation",
                    "timestamp": str(asyncio.get_event_loop().time())
                }
            }
            
            deliverable = await create_deliverable(workspace_id, deliverable_data)
            deliverable_id = deliverable.get("id")
            
            logger.info(f"ðŸŽ‰ Created deliverable {deliverable_id} for workspace {workspace_id}")
            return deliverable_id
        else:
            if force:
                logger.info(f"â³ Force mode but no completed tasks: {len(completed_tasks)} tasks, {len(existing_deliverables)} deliverables")
            else:
                logger.info(f"â³ Not ready for deliverable: {len(completed_tasks)} tasks, {len(existing_deliverables)} deliverables")
            return None
            
    except Exception as e:
        logger.error(f"Error in check_and_create_final_deliverable: {e}", exc_info=True)
        return None

async def _aggregate_task_results(completed_tasks: list) -> tuple[str, float]:
    """Aggregate results from completed tasks and return content and a quality score."""
    try:
        logger.info(f"ðŸ” Starting intelligent aggregation for {len(completed_tasks)} completed tasks")
        
        from ai_agents.deliverable_assembly import deliverable_assembly_agent
        from database import get_workspace # Assuming this function exists to get workspace details

        extractor = unified_deliverable_engine.asset_extractor
        task_assets = await extractor.extract_assets_from_task_batch(completed_tasks)
        
        all_assets = []
        for task_id, assets in task_assets.items():
            all_assets.extend(assets)
        
        if not all_assets:
            logger.warning("No concrete assets extracted from tasks. Aggregation will result in low quality.")
            summary = _create_simple_task_summary(completed_tasks)
            return summary, 10.0 # Return a very low score

        workspace_id = completed_tasks[0].get('workspace_id') if completed_tasks else None
        workspace_context = await get_workspace(workspace_id) if workspace_id else {}
        
        goal_info = completed_tasks[0].get('goal_id') # Simplified goal fetching
        
        deliverable_result = await deliverable_assembly_agent.assemble_deliverable(
            goal_description=str(goal_info), # Pass goal info
            assets=all_assets,
            workspace_context=workspace_context
        )
        
        if deliverable_result.get('status') == 'completed':
            quality_score = deliverable_result.get('quality_score', 0.85) * 100
            logger.info(f"âœ… Intelligent assembly completed with quality score: {quality_score:.2f}")
            return deliverable_result.get('content', ''), quality_score
        else:
            error_content = f"# Deliverable Generation Report\n\nStatus: {deliverable_result.get('status')}\n\n{deliverable_result.get('content', 'No content generated')}"
            return error_content, 20.0 # Low score for failed aggregation
        
    except Exception as e:
        logger.error(f"Error in intelligent aggregation: {e}")
        summary = _create_simple_task_summary(completed_tasks)
        return summary, 15.0 # Low score for fallback summary



def _create_simple_task_summary(completed_tasks: list) -> str:
    """Create a simple task summary as fallback"""
    try:
        summary = ["# Task Summary Report", ""]
        summary.append(f"Total tasks completed: {len(completed_tasks)}")
        summary.append("")
        
        for i, task in enumerate(completed_tasks, 1):
            summary.append(f"## Task {i}: {task.get('name', 'Unnamed Task')}")
            result = task.get('result', 'No result available')
            if isinstance(result, str):
                summary.append(result[:500] + "..." if len(result) > 500 else result)
            else:
                summary.append(str(result)[:500] + "...")
            summary.append("")
        
        return "\n".join(summary)
    except Exception as e:
        return f"Error creating task summary: {str(e)}"

def _format_structured_result(result_dict: dict) -> str:
    """Format structured result dictionary for better readability"""
    try:
        formatted_parts = []
        
        # Handle common structured formats
        if "phases" in result_dict:
            formatted_parts.append("**Project Phases:**")
            phases = result_dict["phases"]
            for phase in phases:
                phase_name = phase.get("phase_name", phase.get("phase", "Unknown Phase"))
                formatted_parts.append(f"- **{phase_name}**")
                
                deliverables = phase.get("deliverables", phase.get("key_deliverables", []))
                if deliverables:
                    for deliverable in deliverables:
                        formatted_parts.append(f"  - {deliverable}")
        
        if "resource_allocation" in result_dict:
            formatted_parts.append("\n**Resource Allocation:**")
            allocation = result_dict["resource_allocation"]
            for phase, resources in allocation.items():
                formatted_parts.append(f"- **{phase}:** {', '.join(resources)}")
        
        if "initial_sub_tasks_phase_1" in result_dict:
            formatted_parts.append("\n**Initial Sub-Tasks:**")
            tasks = result_dict["initial_sub_tasks_phase_1"]
            for task in tasks:
                if isinstance(task, dict):
                    sub_task = task.get("sub_task", task.get("task", "Unknown task"))
                    formatted_parts.append(f"- {sub_task}")
                else:
                    formatted_parts.append(f"- {task}")
        
        if "communication_protocol" in result_dict:
            formatted_parts.append("\n**Communication Protocol:**")
            protocol = result_dict["communication_protocol"]
            for key, value in protocol.items():
                formatted_parts.append(f"- **{key.replace('_', ' ').title()}:** {value}")
        
        # If no specific formatting, show key-value pairs
        if not formatted_parts:
            formatted_parts.append("**Results:**")
            for key, value in result_dict.items():
                if isinstance(value, (str, int, float)):
                    formatted_parts.append(f"- **{key.replace('_', ' ').title()}:** {value}")
                elif isinstance(value, list) and len(value) <= 5:
                    formatted_parts.append(f"- **{key.replace('_', ' ').title()}:** {', '.join(map(str, value))}")
        
        return "\n".join(formatted_parts)
        
    except Exception as e:
        return f"**Result:** {str(result_dict)[:300]}..."

def create_intelligent_deliverable(*args, **kwargs):
    """Backward compatibility function"""
    logger.info("create_intelligent_deliverable called")
    return {}

def deliverable_aggregator(*args, **kwargs):
    """Backward compatibility function"""
    logger.info("deliverable_aggregator called")
    return {}

# Backward compatibility classes
class ConcreteAssetExtractor:
    """Backward compatibility wrapper for real ConcreteAssetExtractor"""
    
    def __init__(self):
        from .concrete_asset_extractor import concrete_asset_extractor
        self.extractor = concrete_asset_extractor
    
    async def extract_assets(self, content: str) -> List[Dict[str, Any]]:
        return await self.extractor.extract_assets(content)

class AIDisplayEnhancer:
    """Backward compatibility class"""
    
    def __init__(self):
        pass

class MultiSourceAssetExtractor:
    """Backward compatibility class"""
    
    def __init__(self):
        pass

class UniversalAIContentExtractor:
    """Backward compatibility class"""
    
    def __init__(self):
        pass

class DeliverableMarkupProcessor:
    """Backward compatibility class"""
    
    def __init__(self):
        pass

class DeliverablePipeline:
    """Backward compatibility class with Pillar 7 autonomous pipeline support"""
    
    def __init__(self):
        self._running = False
        self._autonomous_mode = True  # Always autonomous for Pillar 7 compliance
    
    async def start(self):
        """Start the deliverable pipeline (Pillar 7: Autonomous Pipeline)"""
        import logging
        logger = logging.getLogger(__name__)
        
        try:
            logger.info("ðŸš€ Starting Deliverable Pipeline in autonomous mode...")
            self._running = True
            logger.info("âœ… Deliverable Pipeline started successfully")
            return {"status": "started", "autonomous_mode": self._autonomous_mode}
        except Exception as e:
            logger.error(f"âŒ Failed to start Deliverable Pipeline: {e}")
            self._running = False
            raise e
    
    async def stop(self):
        """Stop the deliverable pipeline"""
        import logging
        logger = logging.getLogger(__name__)
        
        try:
            logger.info("ðŸ›‘ Stopping Deliverable Pipeline...")
            self._running = False
            logger.info("âœ… Deliverable Pipeline stopped successfully")
            return {"status": "stopped"}
        except Exception as e:
            logger.error(f"âŒ Failed to stop Deliverable Pipeline: {e}")
            raise e
    
    def is_running(self) -> bool:
        """Check if the pipeline is running"""
        return self._running

class RequirementsAnalyzer:
    """Backward compatibility class"""
    
    def __init__(self):
        pass

class AssetSchemaGenerator:
    """Backward compatibility class"""
    
    def __init__(self):
        pass

class IntelligentDeliverableAggregator:
    """Backward compatibility class"""
    
    def __init__(self):
        pass

class AIDeliverableAnalyzer:
    """Backward compatibility class"""
    
    def __init__(self):
        pass

class DynamicAssetExtractor:
    """Backward compatibility class"""
    
    def __init__(self):
        pass

class IntelligentDeliverablePackager:
    """Backward compatibility class"""
    
    def __init__(self):
        pass